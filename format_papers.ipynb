{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_paper(html):\n",
    "    #ID\n",
    "    doi = html.find(\"article-id\",{\"pub-id-type\":\"doi\"}).text\n",
    "    #Type\n",
    "    type_ = html.find(\"subj-group\",{\"subj-group-type\":\"heading\"}).text#,{\"subj-group-type\":\"Discipline-v3\"})\n",
    "    #Dates\n",
    "    published = \"/\".join([_.text for _ in html.find(\"pub-date\",{\"pub-type\":\"epub\"})])\n",
    "    received = \"/\".join([_.text for _ in html.find(\"date\",{\"date-type\":\"received\"})])\n",
    "    accepted = \"/\".join([_.text for _ in html.find(\"date\",{\"date-type\":\"accepted\"})])\n",
    "    \n",
    "    #Title\n",
    "    title = html.find(\"article-title\").text.replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"\\r\",\" \")\n",
    "        \n",
    "    #categories\n",
    "    cats = []\n",
    "    for cat in html.find_all(\"subj-group\", {\"subj-group-type\":\"Discipline-v3\"}):\n",
    "        cats.append(cat.find(\"subject\").text)\n",
    "        \n",
    "    cats = \" ::: \".join(list(set(cats)))\n",
    "    return [\"\\t\".join([doi,type_,published,received,accepted,title,cats])]\n",
    "    \n",
    "\n",
    "def write_authors(html):\n",
    "    doi = html.find(\"article-id\",{\"pub-id-type\":\"doi\"}).text\n",
    "    \n",
    "    authors = []\n",
    "    for author in html.find_all(\"contrib\",{\"contrib-type\":\"author\"}):\n",
    "        \n",
    "        #Author name\n",
    "        try:\n",
    "            name = \" ::: \".join([_.text for _ in author.find(\"name\")])\n",
    "        except:\n",
    "            continue #no author, a research group\n",
    "\n",
    "        #Author ID (if available)\n",
    "        orcid = author.find(\"contrib-id\",{\"contrib-id-type\":\"orcid\"})\n",
    "        if orcid is not None:\n",
    "            orcid = orcid.text\n",
    "        else:\n",
    "            orcid = \"\"\n",
    "\n",
    "        #Roles\n",
    "        roles = \" ::: \".join([_.text for _ in author.find_all(\"role\")])\n",
    "\n",
    "        #Addresses\n",
    "        add = []\n",
    "        corr = \"0\"\n",
    "        for aff in author.find_all(\"xref\"):\n",
    "            rid = aff.get(\"rid\")\n",
    "            if \"cor\" in rid:\n",
    "                corr = \"1\"\n",
    "            else:\n",
    "                \n",
    "                try:\n",
    "                    add.append(html.find(\"aff\",{\"id\":rid}).find(\"addr-line\").text)\n",
    "                except:\n",
    "                    pass #other field\n",
    "                    \n",
    "                \n",
    "\n",
    "        add = \" ::: \".join(add)\n",
    "\n",
    "        authors.append(\"\\t\".join([doi,name,orcid,roles,add,corr]))\n",
    "    \n",
    "    return authors        \n",
    "        \n",
    "\n",
    "def write_editor(html):\n",
    "    doi = html.find(\"article-id\",{\"pub-id-type\":\"doi\"}).text\n",
    "    \n",
    "    editors = []\n",
    "    for author in html.find_all(\"contrib\",{\"contrib-type\":\"editor\"}):\n",
    "        #Author name\n",
    "        name = \" ::: \".join([_.text for _ in author.find(\"name\")])\n",
    "\n",
    "        #Addresses\n",
    "        add = []\n",
    "        for aff in author.find_all(\"xref\"):\n",
    "            rid = aff.get(\"rid\")\n",
    "            try:\n",
    "                add.append(html.find(\"aff\",{\"id\":rid}).find(\"addr-line\").text)\n",
    "            except:\n",
    "                pass #another field\n",
    "\n",
    "        add = \" ::: \".join(add)\n",
    "        \n",
    "        editors.append(\"\\t\".join([doi,name,add]))\n",
    "        \n",
    "    return editors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_results(results,f):\n",
    "    \"\"\"\n",
    "    Here fast thing with results (e.g. save to file)\n",
    "    \"\"\"\n",
    "    for line in results:\n",
    "        f.write(line+\"\\n\")  \n",
    "            \n",
    "def create_results(paper):\n",
    "    \"\"\"\n",
    "    Here slow thing with dataframe\n",
    "    \"\"\"\n",
    "    html = bs.BeautifulSoup(open(\"{}{}\".format(path,paper)).read(),\"xml\")\n",
    "    if html.find(\"article\").get(\"article-type\") != 'research-article':\n",
    "        return 0\n",
    "\n",
    "    try:\n",
    "        return [write_paper(html),write_editor(html),write_authors(html)]\n",
    "    except:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"./data_raw/PLoS_One/\"\n",
    "papers = os.listdir(path)\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "with open(\"./data/papers.csv\",\"w+\") as f_paper, \\\n",
    "     open(\"./data/editors.csv\",\"w+\") as f_editor, \\\n",
    "     open(\"./data/authors.csv\",\"w+\") as f_author:\n",
    "            \n",
    "    f_paper.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\"doi\",\"type_\",\"published\",\"received\",\"accepted\",\"title\",\"cats\"))\n",
    "    f_author.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\"doi\",\"name\",\"orcid\",\"roles\",\"add\",\"corr\"))\n",
    "    f_editor.write(\"{}\\t{}\\t{}\\n\".format(\"doi\",\"name\",\"add\"))\n",
    "\n",
    "\n",
    "    with Pool() as pool:\n",
    "        for results in pool.imap_unordered(create_results, papers):\n",
    "            if isinstance(results,int):\n",
    "                skipped += results\n",
    "            else:\n",
    "                process_results(results[0],f_paper)\n",
    "                process_results(results[1],f_editor)\n",
    "                process_results(results[2],f_author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## No need to run, the code above is fixed now\n",
    "previous_fields = \"\"\n",
    "previous_line = 0\n",
    "with open(\"data_raw/papers.csv\") as f,open(\"data_raw/papers_fixed.csv\",\"w+\") as fout:\n",
    "    for line in f:\n",
    "        fields = line.split(\"\\t\")\n",
    "        if (len(fields) == 7):\n",
    "            fout.write(previous_fields)\n",
    "            previous_fields = \"\\t\".join(fields)\n",
    "        elif (len(fields) < 7):\n",
    "            previous_fields = previous_fields.replace(\"\\n\",\"\\t\") + \"\\t\".join(fields)\n",
    "            \n",
    "    fout.write(previous_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv data_raw/papers.csv data_raw/_papers.csv\n",
    "!mv data_raw/papers_fixed.csv data_raw/papers.csv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
