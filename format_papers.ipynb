{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_paper(html):\n",
    "    #ID\n",
    "    doi = html.find(\"article-id\",{\"pub-id-type\":\"doi\"}).text\n",
    "    #Type\n",
    "    type_ = html.find(\"subj-group\",{\"subj-group-type\":\"heading\"}).text#,{\"subj-group-type\":\"Discipline-v3\"})\n",
    "    #Dates\n",
    "    published = \"/\".join([_.text for _ in html.find(\"pub-date\",{\"pub-type\":\"epub\"})])\n",
    "    received = \"/\".join([_.text for _ in html.find(\"date\",{\"date-type\":\"received\"})])\n",
    "    accepted = \"/\".join([_.text for _ in html.find(\"date\",{\"date-type\":\"accepted\"})])\n",
    "    \n",
    "    #Title\n",
    "    title = html.find(\"article-title\").text.replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"\\r\",\" \")\n",
    "        \n",
    "    #categories\n",
    "    cats = []\n",
    "    for cat in html.find_all(\"subj-group\", {\"subj-group-type\":\"Discipline-v3\"}):\n",
    "        cats.append(cat.find(\"subject\").text)\n",
    "        \n",
    "    cats = \" ::: \".join(list(set(cats)))\n",
    "    return [\"\\t\".join([doi,type_,published,received,accepted,title,cats])]\n",
    "    \n",
    "\n",
    "def write_authors(html):\n",
    "    doi = html.find(\"article-id\",{\"pub-id-type\":\"doi\"}).text\n",
    "    \n",
    "    authors = []\n",
    "    for author in html.find_all(\"contrib\",{\"contrib-type\":\"author\"}):\n",
    "        \n",
    "        #Author name\n",
    "        try:\n",
    "            name = \" ::: \".join([_.text for _ in author.find(\"name\")])\n",
    "        except:\n",
    "            continue #no author, a research group\n",
    "\n",
    "        #Author ID (if available)\n",
    "        orcid = author.find(\"contrib-id\",{\"contrib-id-type\":\"orcid\"})\n",
    "        if orcid is not None:\n",
    "            orcid = orcid.text\n",
    "        else:\n",
    "            orcid = \"\"\n",
    "\n",
    "        #Roles\n",
    "        roles = \" ::: \".join([_.text for _ in author.find_all(\"role\")])\n",
    "\n",
    "        #Addresses\n",
    "        add = []\n",
    "        corr = \"0\"\n",
    "        for aff in author.find_all(\"xref\"):\n",
    "            rid = aff.get(\"rid\")\n",
    "            if \"cor\" in rid:\n",
    "                corr = \"1\"\n",
    "            else:\n",
    "                \n",
    "                try:\n",
    "                    add.append(html.find(\"aff\",{\"id\":rid}).find(\"addr-line\").text)\n",
    "                except:\n",
    "                    pass #other field\n",
    "                    \n",
    "                \n",
    "\n",
    "        add = \" ::: \".join(add)\n",
    "\n",
    "        authors.append(\"\\t\".join([doi,name,orcid,roles,add,corr]))\n",
    "    \n",
    "    return authors        \n",
    "        \n",
    "\n",
    "def write_editor(html):\n",
    "    doi = html.find(\"article-id\",{\"pub-id-type\":\"doi\"}).text\n",
    "    \n",
    "    editors = []\n",
    "    for author in html.find_all(\"contrib\",{\"contrib-type\":\"editor\"}):\n",
    "        #Author name\n",
    "        name = \" ::: \".join([_.text for _ in author.find(\"name\")])\n",
    "\n",
    "        #Addresses\n",
    "        add = []\n",
    "        for aff in author.find_all(\"xref\"):\n",
    "            rid = aff.get(\"rid\")\n",
    "            try:\n",
    "                add.append(html.find(\"aff\",{\"id\":rid}).find(\"addr-line\").text)\n",
    "            except:\n",
    "                pass #another field\n",
    "\n",
    "        add = \" ::: \".join(add)\n",
    "        \n",
    "        editors.append(\"\\t\".join([doi,name,add]))\n",
    "        \n",
    "    return editors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_results(results,f):\n",
    "    \"\"\"\n",
    "    Here fast thing with results (e.g. save to file)\n",
    "    \"\"\"\n",
    "    for line in results:\n",
    "        f.write(line+\"\\n\")  \n",
    "            \n",
    "def create_results(paper):\n",
    "    \"\"\"\n",
    "    Here slow thing with dataframe\n",
    "    \"\"\"\n",
    "    html = bs.BeautifulSoup(open(\"{}{}\".format(path,paper)).read(),\"xml\")\n",
    "    if html.find(\"article\").get(\"article-type\") != 'research-article':\n",
    "        return 0\n",
    "\n",
    "    try:\n",
    "        return [write_paper(html),write_editor(html),write_authors(html)]\n",
    "    except:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"./data_raw/PLoS_One/\"\n",
    "papers = os.listdir(path)\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "with open(\"./data/papers.tsv\",\"w+\") as f_paper, \\\n",
    "     open(\"./data/editors.tsv\",\"w+\") as f_editor, \\\n",
    "     open(\"./data/authors.tsv\",\"w+\") as f_author:\n",
    "            \n",
    "    f_paper.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\"doi\",\"type_\",\"published\",\"received\",\"accepted\",\"title\",\"cats\"))\n",
    "    f_author.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\"doi\",\"name\",\"orcid\",\"roles\",\"add\",\"corr\"))\n",
    "    f_editor.write(\"{}\\t{}\\t{}\\n\".format(\"doi\",\"name\",\"add\"))\n",
    "\n",
    "\n",
    "    with Pool() as pool:\n",
    "        for results in pool.imap_unordered(create_results, papers):\n",
    "            if isinstance(results,int):\n",
    "                skipped += results\n",
    "            else:\n",
    "                process_results(results[0],f_paper)\n",
    "                process_results(results[1],f_editor)\n",
    "                process_results(results[2],f_author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No need to run, the code above is fixed now\n",
    "previous_fields = \"\"\n",
    "previous_line = 0\n",
    "with open(\"data_raw/papers.tsv\") as f,open(\"data_raw/papers_fixed.tsv\",\"w+\") as fout:\n",
    "    for line in f:\n",
    "        fields = line.split(\"\\t\")\n",
    "        if (len(fields) == 7):\n",
    "            fout.write(previous_fields)\n",
    "            previous_fields = \"\\t\".join(fields)\n",
    "        elif (len(fields) < 7):\n",
    "            previous_fields = previous_fields.replace(\"\\n\",\"\\t\") + \"\\t\".join(fields)\n",
    "            \n",
    "    fout.write(previous_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv data_raw/papers.tsv data_raw/_papers.tsv\n",
    "!mv data_raw/papers_fixed.tsv data_raw/papers.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(name):\n",
    "    last,first,*_ = name.split(\" ::: \")\n",
    "    path = \"http://abel.lis.illinois.edu/cgi-bin/ethnea/search.py?Fname={0}&Lname={1}&format=json\".format(first, last)\n",
    "    r = requests.get(path)\n",
    "    text = r.text.strip().replace('\\'', '\"')\n",
    "    x = json.loads(text)\n",
    "    gender,ethnic = x['Genni'],x[\"Ethnea\"]\n",
    "    \n",
    "    #for testing\n",
    "    #print(\"{0} {1}\".format(first,last), end=\" --> \")\n",
    "    #print(\"empirical: {0}\".format(empirical))\n",
    "    \n",
    "    return gender,ethnic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_main(type_):\n",
    "    df = pd.read_csv(\"./data/{}.tsv\".format(type_),sep=\"\\t\")\n",
    "    gender_map = dict()\n",
    "    ethnic_map = dict()\n",
    "    \n",
    "    unique_names = df[\"name\"].unique()\n",
    "    for i,name in enumerate(unique_names):\n",
    "        if isinstance(name,float):\n",
    "            continue\n",
    "        if ((i%1000) == 0):\n",
    "            print(\"{:2.2f}\".format(i/len(unique_names)*100),end = \"-\")\n",
    "            \n",
    "        try:\n",
    "            gender_map[name],ethnic_map[name] = get_gender(name)\n",
    "        except:\n",
    "            print(name)\n",
    "            \n",
    "    return df,gender_map,ethnic_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df,gender_map,ethnic_map = gender_main(\"editors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [a for  _ in d.split(\" : \") for a in _.split(\"\\n\") if \":::\" in a]:\n",
    "    gender_map[i],ethnic_map[i] = get_gender(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"] = df[\"name\"].map(gender_map)\n",
    "df[\"ethnicity\"] = df[\"name\"].map(ethnic_map)\n",
    "df.to_csv(\"./data/editors_gender.tsv\",sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>name</th>\n",
       "      <th>orcid</th>\n",
       "      <th>roles</th>\n",
       "      <th>add</th>\n",
       "      <th>corr</th>\n",
       "      <th>gender</th>\n",
       "      <th>eth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1371/journal.pone.0089948</td>\n",
       "      <td>Wang ::: Ze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Psychiatry, Perelman School of M...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>CHINESE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1371/journal.pone.0144963</td>\n",
       "      <td>Wang ::: Ze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhejiang Key Laboratory for Research in Assess...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>CHINESE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1371/journal.pone.0001506</td>\n",
       "      <td>Wang ::: Ze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Psychiatry, University of Pennsy...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>CHINESE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1371/journal.pone.0068238</td>\n",
       "      <td>Wang ::: Ze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>School of Finance, Zhejiang University of Fina...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>CHINESE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1371/journal.pone.0065884</td>\n",
       "      <td>Wang ::: Ze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Center for functional Neuroimaging, Department...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>CHINESE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            doi         name orcid roles  \\\n",
       "0  10.1371/journal.pone.0089948  Wang ::: Ze   NaN   NaN   \n",
       "1  10.1371/journal.pone.0144963  Wang ::: Ze   NaN   NaN   \n",
       "2  10.1371/journal.pone.0001506  Wang ::: Ze   NaN   NaN   \n",
       "3  10.1371/journal.pone.0068238  Wang ::: Ze   NaN   NaN   \n",
       "4  10.1371/journal.pone.0065884  Wang ::: Ze   NaN   NaN   \n",
       "\n",
       "                                                 add  corr gender      eth  \n",
       "0  Department of Psychiatry, Perelman School of M...   1.0      -  CHINESE  \n",
       "1  Zhejiang Key Laboratory for Research in Assess...   0.0      -  CHINESE  \n",
       "2  Department of Psychiatry, University of Pennsy...   0.0      -  CHINESE  \n",
       "3  School of Finance, Zhejiang University of Fina...   0.0      -  CHINESE  \n",
       "4  Center for functional Neuroimaging, Department...   1.0      -  CHINESE  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#authors = pd.read_csv(\"data/authors.tsv\",sep=\"\\t\")\n",
    "#ethnicity = pd.read_csv(\"data/gender_corr.tsv\",sep=\"\\t\",header=None,names=[\"name\",\"gender\",\"eth\"])\n",
    "sample = pd.merge(authors,ethnicity)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.loc[sample[\"gender\"] != ]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
